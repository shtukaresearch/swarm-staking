\maketitle
%\thispagestyle{fancy}
\section*{Overview}

\subsection*{Goals}

Our goals for this month were as follows: 

\begin{itemize}
  \item 
    Begin formalising game-theoretic arguments sketched last month in a stochastic setting.
    %
    Incorporate details such as operating cost, amortised capex, and the stake threshold.
  \item
    Introduce parametrised generalisations of the model and hence contextualise SWIPs 19 and 20 in a broader framework.
  \item 
    Consider risk models and their dependence on operator scale.
  \item
    Revise and expand our formulation of the NO incentive system design objectives.
\end{itemize}

\subsection*{Methodology}

For evaluating risk associated with the redistribution lottery, we used a random walks approach together with the standard actuarial measures value-at-risk and ruin probability.
%
We also developed a Python notebook to analyse risk models and compute metrics at different scales. The notebook is available at the GitHub repo for this project.\footnote{\url{https://github.com/shtukaresearch/swarm-staking/blob/main/notebooks/risk-model.ipynb}}

We approached the parametrised generalisation of the incentive model by direct inspection of the action spaces and state transition functions to see where parameters and binary design choices can be introduced, especially where these admit interpretations in traditional financial terms. 
%
Parameters were chosen to be able to describe changes proposed in SWIPs 19 and 20.


\subsection*{Scope}

The scope of this month's work is the node operator incentive system, which includes the rules surrounding the stake registry and redistribution mechanism. 
%
We introduce the storage unit price oracle and treat it as a black box.

We introduced parameters to generalise the model and incorporated the changes in SWIPs 19\footnote{\url{https://github.com/ethersphere/SWIPs/blob/master/SWIPs/swip-19.md}} and 20\footnote{\url{https://github.com/ethersphere/SWIPs/blob/master/SWIPs/swip-20.md}}, which are implemented as of Version 2.2 of the Bee client, released this month.\footnote{\url{https://github.com/ethersphere/bee/releases/tag/v2.2.0}}

For the risk model, we continued to assume each node is associated with a fixed amount of storage. That is, we did not take into account SWIP-21.\footnote{\url{https://github.com/ethersphere/SWIPs/pull/56}}

\section*{Operations management}

\subsection*{Completed Milestones}

\begin{itemize}
  \item 
    Expand on candidate list of quantitative objectives for the Swarm staking system.
  \item 
    Develop stochastic perfect information model that captures core aspects of the current staking system. 
    %
    Use solutions to the deterministic model to back out results that hold in expectation.

  \item Study staker decision processes and risks without the assumptions of determinism.

  \item Introduce model parameters to incorporate generalisations, including those expressed in SWIPs 19 and 20.
\end{itemize}

\subsection*{Future milestones}
\begin{itemize}  
  \item Study staker decision processes without the assumptions of complete information or stationarity.
  \item Pull data on historic staker behaviour and analyse it in the context of our model. Are there any stakers that already exhibit strategic behaviour? How frequent are instances of direct competition in acquiring stake positions? Create visualisations.
  \item Establish conditions for market clearing at the target replication rate.
  \item Identify aggregate economic indicators and metrics relevant for monitoring and forecasting Swarm storage performance and making decisions about improvements.
\end{itemize}

\subsection*{Revised milestones}

\begin{itemize}
  \item Numerical solution of Bellman equation for $n$-step strategies in the stochastic setting. 
  
  Under perfect information and stationarity, optimal $n$-step strategies terminate in one step, so numerical approaches are not needed.
  %
  Under incomplete information, we expect the outcomes to be quite sensitive to model selection, so some theoretical work is needed before practical computations are possible.

\end{itemize}

\subsection*{Schedule}

\paragraph{October} 
Study aggregate economic indicators and price discovery.
%
Study the effect of different model feature choices through the lens of market efficiency.
%
Introduce time lag effects. 

\paragraph{November} Compile formal LaTeX report. Draft SWIP[s] if alternative proposals are to be accepted.

\paragraph{December} \emph{fin}




\newpage
\section*{Findings}

\begin{comment}
\subsection*{Summary}

\begin{itemize}
  \item 
  \item We studied risk of drawdowns and ruin for NOs of different sizes and its dependence on the reward lottery structure.
  \item We couched the pre-2.2 stake system and SWIPs 19 and 20 in a language of equity and options which aids intuition.
  %
  The objective of this activity was to formulate a generalised model that incorporates current proposals and is flexible enough to provide a common language for the evaluation of future proposals.
  %
  This framework is not yet complete.
\end{itemize}
\end{comment}

\subsection*{Objectives of the NO incentive system design}

We revised and clarified our approach to defining system design objectives.

\subsubsection*{Incentivise provision of the storage service}

The most fundamental objective of the NO incentive system is to incentivise providing storage.\footnote{We thank Viktor Tr\`on for pointing this out.}
%
A simple quantitative interpretation of this objective is as follows: each epoch, Swarm offers an amount of revenue $R_t$ in exchange for the provision of $K_t$ bytes of storage capacity.
%
Then in (some suitably chosen notion of) equilibrium, there should be enough operating nodes to store the requested number of bytes at the target replication rate.

The component of the NO incentive system that controls for this objective is the price oracle: if storage is underprovisioned, increasing the unit price of storage both attracts more supply and attenuates $K_t$.
%
Conversely, if storage is overprovisioned, it manifests as a replication rate over the target, and a reduction in unit price has the opposite effect.

\subsubsection*{Competitiveness, decentralisation, and efficiency}

We posit that the criteria ``low returns to operator scale'' and ``cost of entry'' are explained by underlying objectives of \emph{decentralisation} or \emph{competitiveness}.
%
The intention is that the NO market should not be susceptible to monopolistic or oligopolistic market structure where some participants acquire market power.

Decentralisation can be assessed in the present by calculating a measure of decentralisation such as the Shannon entropy or Herfindahl-Hirschman index (a.k.a.~$L^2$-norm).
%
For example, if the ideal stake distribution in any neighbourhood is evenly weighted among 4 nodes, then the target entropy is $\log(4)=2$ bits.

We can also use our models to assess the propensity of the system to become centralised in the future.
%
Here are some of the model features we have studied, interpreted in this light:
\begin{enumerate}
  \item \emph{Investment landscape for new entrants.} If a new opportunity arises, for example because overall network revenue prospects have improved, there is room to deploy capital via new entrants rather than incumbents. (This is related to the cost of entry and returns to scale criteria considered last month.)
  \item \emph{Dispersion of the operating cost distribution.} An NO should not need the absolute minimum operating cost in the market to be able to compete. Operating costs among NOs should be somewhat dispersed. (Since large scale tends to be associated with low operating costs, this is also a returns to scale feature.) 
  \item \emph{Cost of risk at different scales.} Small node operations should not be unviable because of risk issues. The community should agree on a practical threshold for ``small.'' (We called this feature ``variance of rewards'' last month.)
\end{enumerate}

We also considered the tradeoff between decentralisation and \emph{efficiency}.
%
Roughly speaking, the Swarm Protocol is efficient if lower average NO costs result in lower prices for consumers.
%
A criterion of efficiency is that NOs with lower operating costs can achieve a larger market share; this criterion competes with that of decentralisation.

\begin{comment}
\subsubsection*{List of objectives}

Here are the revised candidate objectives for the NO incentive system:

\begin{enumerate}
  \item \emph{Incentivise service provision.} See above.
  \item \emph{Sybil resistance.} See August report.
  \item \emph{Penalising safety replication failures.} Nodes that fail to report storage proofs for the ``correct'' set of chunks for their neighbourhood should be penalised by having their stake slashed and hence their authorisation to participate in redistribution revoked.
  
  Replication failures are a failure of consensus, hence arguably a type of \emph{safety fault}, not a liveness fault as indicated in last month's report.
  %
  However, the replication consensus system itself is 

  \item \emph{Limited returns to operator scale.} See above.
  \item \emph{Create or accentuate demand pressure for BZZ token.} See August report.
\end{enumerate}
\end{comment}

\subsection*{Risk parameters}

Risk comes into play through all random or unknown elements of the model: total network revenue, operating costs, the lottery determining who receives the payout in each epoch, and the unknown incentive functions and strategies of other NOs.
%
This month we focused on the best-controlled source of risk: the redistribution lottery.

Risk management is a cost of doing business that factors into agents' operating cost $O$.
%
Since smaller operators are typically both more exposed to risk and less able to accurately estimate it, they bear a disproportionate cost in accounting for risk which hampers their productivity.
%
Thus quantifying the effects of NO and network scaling on risk helps us understand the tradeoff between decentralisation and efficiency of the market as a whole.

\begin{comment}
\subsubsection*{Redistribution lottery structure}
 
A risk factor that is straightforwardly under the direct control of the system is the structure of the redistribution lottery.
%
Currently, in each epoch the full redistribution payout is awarded to a single NO with probability weighted by the number of bins and the NO share within the target bin.
%
Clearly, such an approach has higher variance than the expectation-equivalent deterministic system, which doles out a share of the payout weighted by the number of bins and bin share with probability $1$.

The random approach saves on computational costs by reducing the number of transfers that must be made in each epoch.
%
On the other hand, it introduces a risk of drawdowns and bankruptcy that especially affects smaller scale NOs, who may experience long strings of epochs without receiving any payout.
\end{comment}

\paragraph{Model}

We studied a model where an NO starts with initial operating cash $C_0$ and has constant per epoch operating cost $O>0$.
%
We assumed share distribution is fixed and the per epoch network revenue is a constant $R>0$.
%
Each epoch, our target NO receives $R$ with probability $p\in[0,1]$; if there are $2^D$ neighbourhoods and he holds a share weight $0<w\leq 1$ in his neighbourhood, then $p=2^{-D}w$.
%
Assuming no cash is withdrawn, the operating cash in epoch $n$ is governed by
\[
  C_n = C_0 - nO + RU_n \qquad\text{where}\qquad U_n\sim \mathrm{Binom}(n,p).
\]
In particular, it is linear in a binomial random variable $U_n$, and risk parameters can therefore be computed in terms of the binomial distribution.

\paragraph{No payout} A naive first approximation to the risk of ruin is the probability $(1-p)^{\left\lfloor C_0/O \right\rfloor}$ of \emph{never} receiving a single payout before going bust.
  %
  This value is a lower bound for the risk of ruin; depending on the relative size of $p$, $C_0/O$, and $R/O$, it may not be very tight.

\paragraph{VaR} A widely used risk measure is the value-at-risk (VaR) at probability $q\in(0,1)$, which is the largest cash reserve level $K$ such that $\mathbb{P}(C_n\geq K)\geq q$, a.k.a.~the quantile function of $K$ evaluated at $q$.
  %
  This can be computed quite efficiently for binomial variables; see the attached notebooks.
  
  VaR does not register larger drawdowns before the end of the period, nor does it track the size of losses that occur if losses do exceed the threshold.
  
\paragraph{Eventual ruin}
    The true ruin probability $\Prob(T_{\leq 0}<N)$, where $N\in\N\cup\{\infty\}$ is the investment horizon and $T_{\leq 0}\in\N$ is the first epoch $t$ at which $C_t\leq 0$, is of course more complicated to compute.
    %
    As the number of sample paths scales like $2^N$, a brute force approach soon draws out of reach as $N$ increases.

    In the discrete setting, the hitting time theorem gives us a route to an exact form.
    %
    To achieve this, rescale the unit of account so that $O=1$ and assume that $R$ and $C_0$ are exact integer multiples of $O$.\footnote{Though artificial, this adjustment is harmless when $O\ll C_0,R$.}
    %
    Then $C_n$ is a left continuous random walk with step size $RX - 1$, where $X\sim\mathrm{Bernoulli}(p)$, and the hitting time theorem gives us
    \[
      \Prob(T_0 = n) = \frac{C_0}{n}\Prob(C_n = 0).
    \]
    Summing up over all $n$ and $C_0$, we may compute the generating function of these numbers using the elementary formula $\Expectation[z^{U_n}] = ((1-p) + pz)^n$ for the PGF of the binomial distribution, from which can be extracted closed forms for the ruin probabilities.
    %
    Alternatively, the RHS can be computed directly quite quickly using a computer.    

\

Empirically, with $C_0$ set to three months of operating costs and a network depth of $D=11$, corresponding to a total network storage capacity of $32$TiB, the probability of ruin in finite time for a small operator with 1 node, resp.~16 nodes, is at least $77.36\%$, resp.~$5.07\%$.
    
With the full network at exabyte scale ($D=26$) and per node revenue conditions similar to the present network, the situation for a 16-node operator is stark: we have a $0.9975$ probability of receiving no rewards in a year.
%
On the other hand, the payout in the unlikely case of receiving a reward before the cash reserve runs out is so large that ruin cannot occur again for 437 years.\footnote{These numbers were produced using mildly hacked prices of AWS EC2 instances, the current Swarm network reward pot as reported on \url{https://www.ethswarm.org/get-bzz}, and a plausible BZZ/USD price.}

\subsection*{Parametrising the redistribution mechanism}

We explored ways to introduce parameters into the NO incentive mechanism so as to consider both proposed and hitherto unexplored variants on an equal footing.

\paragraph{Pricing shares}

A position in the Swarm stake registry can be interpreted as an \emph{equity share} in the neighbourhood that pays dividends on the neighbourhood's future revenue.
%
Adding more stake causes more shares to be minted, resulting in \emph{dilution} of the outstanding shares.

We believe that the language of equity, issuance, and dilution makes the financial structure of the staking system more intuitively clear, and recommend that this terminology be introduced into the Swarm Protocol communication strategy.

The number of shares corresponding to a balance in the stake registry is a matter of convention, the most natural one being that $1$ share equals $1$ staked PLUR.
%
If non-integer numbers of shares are allowed, any price $p\in\N_+$ leads to a convention where $1$ share equates to $p$ PLUR in the stake registry.
%
For example, a convenient choice might be to set $p=10^{16}$, i.e.~$1$ BZZ.
%
This choice does not affect any dynamics of the model.

A true generalisation is to introduce a dynamic share price $p_t$.
%
SWIP-20 introduces such a scheme and explicitly names the equity balance as a new field of \emph{committed stake}.
%
Under SWIP-20, $p_t$ is the unit price of storage as provided by the price oracle contract in that epoch.

\paragraph{Optionality}

An \emph{optionality} on a share is an action that the holder can choose to take that ``burns'' it in exchange for some other asset.
%
Optionality on shares makes it easier to develop adaptive strategies, hence makes the game more accessible to less sophisticated NOs.

  SWIPs 19 and 20 introduce optionalities on neighbourhood shares. To be precise:
  \begin{itemize}
    \item Neighbourhood hopping can be seen as an option to \emph{convert} shares in one bin to shares in another bin on a one-to-one basis.
    \item The ``excess stake'' withdrawal introduced in SWIP-20 can be understood as an option to \emph{redeem} shares at the price at which they were bought and immediately repurchase at the current market price.
    %
    Redemption without repurchase is not allowed.
    %
    Note however that this interpretation requires us to posit a different asset type for shares purchased at different prices.
  \end{itemize}
\begin{comment}
\subsubsection*{Assumptions of the current model}

This month we were able to lift some of the assumptions of the model we studied in August, but quite a few remain:
\begin{itemize}
  \item Perfect information: all players know the strategies of the other players at all future steps. Perhaps a more realistic approach is to model the mechanism as a (dynamic) Bayes game of incomplete information.
  \item Stationarity: the (expected) revenue of the target neighbourhood remains constant. In reality, expected revenue is affected by network demand, the decisions of stakers via the price oracle, and the price of competing services.
  %
  Similarly, operational costs depend on the costs of hardware and electricity.
  \item We considered all costs and rewards as BZZ denominated. But operational costs and the time preference discount rate $r$ are more easily modelled in terms of fiat currency.
  \item We didn't model any time delays between stake top-ups and reward weight updates.
  \item We didn't model the risk of being frozen or slashed due to liveness failures.
  \item We didn't incorporate changes to the gate function introduced in SWIP-20.
  \item We assumed the neighbourhood count remains constant.
\end{itemize}
\end{comment}